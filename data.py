import streamlit as st
import pandas as pd
import numpy as np
from scipy.stats import zscore, pearsonr
from sklearn.ensemble import IsolationForest
from sklearn.decomposition import PCA
import seaborn as sns
import matplotlib.pyplot as plt
import io
import matplotlib as mpl
import matplotlib.font_manager
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
import os
import base64

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'KaiTi', 'Arial Unicode MS', 'DejaVu Sans']  # æ·»åŠ æ›´å¤šå­—ä½“é€‰é¡¹
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

# è®¾ç½®å›¾è¡¨æ ·å¼
plt.style.use('seaborn')
sns.set_style("whitegrid")
sns.set_context("notebook", font_scale=1.2)

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="AIæµ·å¤–åº”ç”¨åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ·»åŠ é¡µé¢æ ‡é¢˜å’Œè¯´æ˜
st.title("ğŸ“Š AIæµ·å¤–åº”ç”¨æ•°æ®åˆ†ææŠ¥å‘Š")
st.markdown("""
æœ¬åº”ç”¨ç”¨äºåˆ†æAIæµ·å¤–åº”ç”¨çš„å‘å±•çŠ¶å†µï¼ŒåŒ…æ‹¬ï¼š
- ä¼ä¸šè¥æ”¶åˆ†æ
- èèµ„æƒ…å†µåˆ†æ
- å‘å±•é˜¶æ®µåˆ¤æ–­
- å¼‚å¸¸å€¼æ£€æµ‹
""")

# æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½
uploaded_file = st.file_uploader("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶ (AIæµ·å¤–åº”ç”¨ 20250408.xlsx)", type=['xlsx'])

# å®šä¹‰å­—ä½“å›é€€å‡½æ•°
def plot_with_fallback_font(fig, ax):
    try:
        # å°è¯•ä½¿ç”¨ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'KaiTi']
        st.pyplot(fig)
    except:
        # å¦‚æœä¸­æ–‡å­—ä½“å¤±è´¥ï¼Œä½¿ç”¨è‹±æ–‡æ˜¾ç¤º
        plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']
        # å°†ä¸­æ–‡æ ‡ç­¾è½¬æ¢ä¸ºè‹±æ–‡
        if hasattr(ax, 'set_title'):
            ax.set_title(ax.get_title().replace('å˜é‡ç›¸å…³æ€§çƒ­åŠ›å›¾', 'Correlation Heatmap'))
        if hasattr(ax, 'set_xlabel'):
            ax.set_xlabel(ax.get_xlabel().replace('ç¬¬ä¸€ä¸»æˆåˆ†', 'First Principal Component'))
        if hasattr(ax, 'set_ylabel'):
            ax.set_ylabel(ax.get_ylabel().replace('ç¬¬äºŒä¸»æˆåˆ†', 'Second Principal Component'))
        st.pyplot(fig)

# è¯»å–æ•°æ®
@st.cache_data
def load_data(uploaded_file):
    try:
        if uploaded_file is None:
            st.warning("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶")
            st.stop()
            
        # è¯»å–æ•°æ®ï¼Œä¿ç•™æ‰€æœ‰åˆ—
        df = pd.read_excel(uploaded_file, sheet_name="source")
        
        # æ˜¾ç¤ºåŸå§‹æ•°æ®ä¿¡æ¯
        st.write("åŸå§‹æ•°æ®ä¿¡æ¯:")
        st.write("åˆ—å:", df.columns.tolist())
        st.write("æ•°æ®ç±»å‹:", df.dtypes)
        st.write("æ•°æ®é¢„è§ˆ:")
        st.dataframe(df.head().astype(str))
        st.write("æ•°æ®å½¢çŠ¶:", df.shape)
        
        # åˆ†ç¦»æ–‡æœ¬åˆ—å’Œæ•°å€¼åˆ—
        text_cols = ['å…¬å¸å', 'AIè¡Œä¸šåˆ†ç±»']  # å‰ä¸¤åˆ—æ˜¯å…¬å¸åå’Œè¡Œä¸š
        numeric_cols = ['å¹´è¥æ”¶ä¼°æµ‹\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰', 'ä¸Šè½®èèµ„é¢\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰', 'ç´¯è®¡èèµ„é¢\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰']  # åä¸‰åˆ—æ˜¯æ•°å€¼æ•°æ®
        
        # åˆ›å»ºæ–°çš„DataFrameä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        processed_df = df.copy()
        
        # ç¡®ä¿æ–‡æœ¬åˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹
        for col in text_cols:
            processed_df[col] = processed_df[col].fillna('').astype(str)
        
        # æ¸…ç†æ•°å€¼æ•°æ®
        for col in numeric_cols:
            # å…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå»é™¤å¯èƒ½çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
            processed_df[col] = processed_df[col].astype(str).str.strip()
            # å°†ç©ºå­—ç¬¦ä¸²å’Œ'nan'è½¬æ¢ä¸ºNaN
            processed_df[col] = processed_df[col].replace(['', 'nan', 'NaN', 'None'], np.nan)
            # è½¬æ¢ä¸ºæ•°å€¼
            processed_df[col] = pd.to_numeric(processed_df[col], errors='coerce')
        
        # åˆ é™¤åŒ…å«NaNçš„è¡Œ
        processed_df = processed_df.dropna()
        
        # ç¡®ä¿æ•°å€¼åˆ—éƒ½æ˜¯floatç±»å‹
        for col in numeric_cols:
            processed_df[col] = processed_df[col].astype(float)
        
        # æŒ‰å¹´è¥æ”¶æ’åº
        processed_df = processed_df.sort_values(by='å¹´è¥æ”¶ä¼°æµ‹\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰', ascending=True)
        
        # æ˜¾ç¤ºæ¸…ç†åçš„æ•°æ®ä¿¡æ¯
        st.write("æ¸…ç†åçš„æ•°æ®ä¿¡æ¯:")
        st.write("åˆ—å:", processed_df.columns.tolist())
        st.write("æ•°æ®ç±»å‹:", processed_df.dtypes)
        st.write("æ•°æ®é¢„è§ˆ:")
        st.dataframe(processed_df.head().astype(str))
        st.write("æ•°æ®å½¢çŠ¶:", processed_df.shape)
        
        return processed_df, text_cols, numeric_cols
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½é”™è¯¯: {str(e)}")
        st.write("è¯·ç¡®ä¿ä¸Šä¼ æ­£ç¡®çš„æ•°æ®æ–‡ä»¶ã€‚")
        st.stop()

# åŠ è½½æ•°æ®
if uploaded_file is not None:
    try:
        df, text_cols, numeric_cols = load_data(uploaded_file)
        
        # æ˜¾ç¤ºåŒ…å«å…¬å¸åå’Œè¡Œä¸šçš„æ•°æ®é¢„è§ˆ
        st.subheader("ğŸ” æ•°æ®é¢„è§ˆ")
        display_df = df[text_cols + ['å¢é•¿ç‡', 'å‘å±•é˜¶æ®µ']].copy()
        for col in display_df.columns:
            display_df[col] = display_df[col].astype(str)
        st.dataframe(display_df.head())

        # æè¿°ç»Ÿè®¡ï¼ˆä»…æ•°å€¼åˆ—ï¼‰
        st.subheader("ğŸ“ˆ æè¿°æ€§ç»Ÿè®¡")
        st.dataframe(df[numeric_cols].describe().astype(str))

        # é˜¶æ®µåˆ†å¸ƒç»Ÿè®¡
        st.subheader("ğŸ“Š å‘å±•é˜¶æ®µåˆ†å¸ƒ")
        stage_counts = df['å‘å±•é˜¶æ®µ'].value_counts()
        st.bar_chart(stage_counts)

        # æ˜¾ç¤ºå„é˜¶æ®µå…¬å¸è¯¦æƒ…
        st.subheader("ğŸ“‹ å„é˜¶æ®µå…¬å¸è¯¦æƒ…")
        for stage in ['æ­£å¸¸æœŸ', 'æ‰©å¼ æœŸ', 'æ³¡æ²«æœŸ']:
            st.write(f"### {stage}å…¬å¸åˆ—è¡¨")
            stage_companies = df[df['å‘å±•é˜¶æ®µ'] == stage][text_cols + ['å¢é•¿ç‡']]
            display_df = stage_companies.copy()
            for col in display_df.columns:
                display_df[col] = display_df[col].astype(str)
            st.dataframe(display_df)

        # ç›¸å…³æ€§åˆ†æ
        st.subheader("ğŸ“ ç›¸å…³æ€§åˆ†æï¼ˆçš®å°”é€Šï¼‰")
        corr_matrix = df[numeric_cols].corr()
        st.write("ğŸ“Š ç›¸å…³çŸ©é˜µï¼š")
        st.dataframe(corr_matrix)

        # ç›¸å…³æ€§çƒ­å›¾
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax, fmt='.2f')
        plt.title('Correlation Heatmap', fontsize=12)
        plot_with_fallback_font(fig, ax)

        # æ˜¾è‘—æ€§æ£€éªŒ
        st.write("ğŸ§ª æ˜¾è‘—æ€§ï¼ˆp < 0.05ï¼‰")
        cols = numeric_cols
        sig_result = []
        for i in range(len(cols)):
            for j in range(i + 1, len(cols)):
                r, p = pearsonr(df[cols[i]], df[cols[j]])
                sig_result.append((cols[i], cols[j], round(r, 3), "{:.3e}".format(p), "âœ…" if p < 0.05 else "âŒ"))
        sig_df = pd.DataFrame(sig_result, columns=["Variable 1", "Variable 2", "Correlation", "p-value", "Significant"])
        st.dataframe(sig_df)

        # å¼‚å¸¸å€¼æ£€æµ‹
        st.subheader("ğŸš¨ å¼‚å¸¸å€¼æ£€æµ‹")
        numeric_df = df[numeric_cols]

        # æ–¹æ³•1ï¼šZ-score
        z_scores = numeric_df.apply(zscore)
        z_outliers = (z_scores.abs() > 3).any(axis=1)

        # æ–¹æ³•2ï¼šIQR
        Q1 = numeric_df.quantile(0.25)
        Q3 = numeric_df.quantile(0.75)
        IQR = Q3 - Q1
        iqr_outliers = ((numeric_df < (Q1 - 1.5 * IQR)) | (numeric_df > (Q3 + 1.5 * IQR))).any(axis=1)

        # æ–¹æ³•3ï¼šIsolation Forest
        iso = IsolationForest(contamination=0.05, random_state=42)
        iso_outliers = iso.fit_predict(numeric_df)
        iso_mask = iso_outliers == -1

        # æ±‡æ€»
        combined_outliers = z_outliers | iqr_outliers | iso_mask
        outlier_df = df[text_cols + numeric_cols + ['å¢é•¿ç‡', 'å‘å±•é˜¶æ®µ']][combined_outliers]

        st.write(f"ğŸ”º Z-score å¼‚å¸¸å€¼æ•°é‡: {z_outliers.sum()}")
        st.write(f"ğŸ”º IQR å¼‚å¸¸å€¼æ•°é‡: {iqr_outliers.sum()}")
        st.write(f"ğŸ”º Isolation Forest å¼‚å¸¸å€¼æ•°é‡: {np.sum(iso_mask)}")
        st.write(f"âœ… åˆå¹¶å¼‚å¸¸å€¼æ•°é‡ï¼ˆå»é‡åï¼‰: {combined_outliers.sum()}")

        st.dataframe(outlier_df)

        # ä¸‹è½½æŒ‰é’®
        to_download = outlier_df.copy()
        csv = to_download.to_csv(index=False).encode()
        st.download_button("ğŸ“¥ ä¸‹è½½å¼‚å¸¸å€¼æ•°æ®", csv, "å¼‚å¸¸å€¼ç»“æœ.csv", "text/csv")

        # PCA å¯è§†åŒ–
        st.subheader("ğŸ§¬ PCA Dimensionality Reduction Visualization")
        pca = PCA(n_components=2)
        components = pca.fit_transform(numeric_df)

        fig2, ax2 = plt.subplots(figsize=(10, 8))
        scatter = ax2.scatter(components[:, 0], components[:, 1], 
                            c=df['å¢é•¿ç‡'], cmap='viridis', alpha=0.7)
        plt.colorbar(scatter, label='Growth Rate (%)')

        # æ·»åŠ é˜¶æ®µæ ‡ç­¾
        stage_mapping = {
            'æ­£å¸¸æœŸ': 'Normal Period',
            'æ‰©å¼ æœŸ': 'Expansion Period',
            'æ³¡æ²«æœŸ': 'Bubble Period'
        }

        for stage in df['å‘å±•é˜¶æ®µ'].unique():
            mask = df['å‘å±•é˜¶æ®µ'] == stage
            ax2.scatter(components[mask, 0], components[mask, 1], 
                       label=stage_mapping[stage], alpha=0.7)

        ax2.set_xlabel(f"First Principal Component (Explained Variance: {pca.explained_variance_ratio_[0]*100:.2f}%)", fontsize=10)
        ax2.set_ylabel(f"Second Principal Component (Explained Variance: {pca.explained_variance_ratio_[1]*100:.2f}%)", fontsize=10)
        ax2.set_title("PCA Results and Development Stage Distribution", fontsize=12)
        ax2.legend(fontsize=10)
        st.pyplot(fig2)

    except Exception as e:
        st.error(f"æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
        st.write("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¸Šä¼ ã€‚")
else:
    st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶") 
