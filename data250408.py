import streamlit as st
import pandas as pd
import numpy as np
from scipy.stats import zscore, pearsonr
from sklearn.ensemble import IsolationForest
from sklearn.decomposition import PCA
import seaborn as sns
import matplotlib.pyplot as plt
import io
import matplotlib as mpl
import matplotlib.font_manager
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
import os
import base64

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'KaiTi']  # æ·»åŠ æ›´å¤šä¸­æ–‡å­—ä½“é€‰é¡¹
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="AIæµ·å¤–åº”ç”¨åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ·»åŠ é¡µé¢æ ‡é¢˜å’Œè¯´æ˜
st.title("ğŸ“Š AIæµ·å¤–åº”ç”¨æ•°æ®åˆ†ææŠ¥å‘Š")
st.markdown("""
æœ¬åº”ç”¨ç”¨äºåˆ†æAIæµ·å¤–åº”ç”¨çš„å‘å±•çŠ¶å†µï¼ŒåŒ…æ‹¬ï¼š
- ä¼ä¸šè¥æ”¶åˆ†æ
- èèµ„æƒ…å†µåˆ†æ
- å‘å±•é˜¶æ®µåˆ¤æ–­
- å¼‚å¸¸å€¼æ£€æµ‹
""")

# æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½
uploaded_file = st.file_uploader("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶ (AIæµ·å¤–åº”ç”¨ 20250408.xlsx)", type=['xlsx'])

# è¯»å–æ•°æ®
@st.cache_data
def load_data(uploaded_file):
    try:
        if uploaded_file is None:
            st.warning("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶")
            st.stop()
            
        # è¯»å–æ•°æ®ï¼Œä¿ç•™æ‰€æœ‰åˆ—
        df = pd.read_excel(uploaded_file, sheet_name="source")
        
        # æ˜¾ç¤ºåŸå§‹æ•°æ®ä¿¡æ¯
        st.write("åŸå§‹æ•°æ®ä¿¡æ¯:")
        st.write("åˆ—å:", df.columns.tolist())
        st.write("æ•°æ®ç±»å‹:", df.dtypes)
        st.write("æ•°æ®é¢„è§ˆ:")
        st.dataframe(df.head().astype(str))
        st.write("æ•°æ®å½¢çŠ¶:", df.shape)
        
        # åˆ†ç¦»æ–‡æœ¬åˆ—å’Œæ•°å€¼åˆ—
        text_cols = ['å…¬å¸å', 'AIè¡Œä¸šåˆ†ç±»']  # å‰ä¸¤åˆ—æ˜¯å…¬å¸åå’Œè¡Œä¸š
        numeric_cols = ['å¹´è¥æ”¶ä¼°æµ‹\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰', 'ä¸Šè½®èèµ„é¢\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰', 'ç´¯è®¡èèµ„é¢\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰']  # åä¸‰åˆ—æ˜¯æ•°å€¼æ•°æ®
        
        # åˆ›å»ºæ–°çš„DataFrameä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        processed_df = df.copy()
        
        # ç¡®ä¿æ–‡æœ¬åˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹
        for col in text_cols:
            processed_df[col] = processed_df[col].fillna('').astype(str)
        
        # æ¸…ç†æ•°å€¼æ•°æ®
        for col in numeric_cols:
            # å…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå»é™¤å¯èƒ½çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
            processed_df[col] = processed_df[col].astype(str).str.strip()
            # å°†ç©ºå­—ç¬¦ä¸²å’Œ'nan'è½¬æ¢ä¸ºNaN
            processed_df[col] = processed_df[col].replace(['', 'nan', 'NaN', 'None'], np.nan)
            # è½¬æ¢ä¸ºæ•°å€¼
            processed_df[col] = pd.to_numeric(processed_df[col], errors='coerce')
        
        # åˆ é™¤åŒ…å«NaNçš„è¡Œ
        processed_df = processed_df.dropna()
        
        # ç¡®ä¿æ•°å€¼åˆ—éƒ½æ˜¯floatç±»å‹
        for col in numeric_cols:
            processed_df[col] = processed_df[col].astype(float)
        
        # æŒ‰å¹´è¥æ”¶æ’åº
        processed_df = processed_df.sort_values(by='å¹´è¥æ”¶ä¼°æµ‹\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰', ascending=True)
        
        # æ˜¾ç¤ºæ¸…ç†åçš„æ•°æ®ä¿¡æ¯
        st.write("æ¸…ç†åçš„æ•°æ®ä¿¡æ¯:")
        st.write("åˆ—å:", processed_df.columns.tolist())
        st.write("æ•°æ®ç±»å‹:", processed_df.dtypes)
        st.write("æ•°æ®é¢„è§ˆ:")
        st.dataframe(processed_df.head().astype(str))
        st.write("æ•°æ®å½¢çŠ¶:", processed_df.shape)
        
        return processed_df, text_cols, numeric_cols
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½é”™è¯¯: {str(e)}")
        st.write("è¯·ç¡®ä¿ä¸Šä¼ æ­£ç¡®çš„æ•°æ®æ–‡ä»¶ã€‚")
        st.stop()

# åˆå§‹åŒ–å˜é‡
df = None
text_cols = []
numeric_cols = []

# åŠ è½½æ•°æ®
if uploaded_file is not None:
    df, text_cols, numeric_cols = load_data(uploaded_file)

# åªæœ‰åœ¨æˆåŠŸåŠ è½½æ•°æ®åæ‰æ‰§è¡Œåç»­æ“ä½œ
if df is not None and len(df) > 0:
    # æ·»åŠ å¢é•¿ç‡è®¡ç®—
    try:
        # ä½¿ç”¨å¹´è¥æ”¶ä¼°æµ‹è®¡ç®—å¢é•¿ç‡
        revenue_col = 'å¹´è¥æ”¶ä¼°æµ‹\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰'
        funding_col = 'ä¸Šè½®èèµ„é¢\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰'
        total_funding_col = 'ç´¯è®¡èèµ„é¢\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰'
        
        # è®¡ç®—å¢é•¿ç‡
        df['å¢é•¿ç‡'] = df[revenue_col].pct_change() * 100
        
        # æŒ‰è¥æ”¶åŒºé—´åˆ†ç»„
        # å®šä¹‰è¥æ”¶åŒºé—´
        # è¯´æ˜ï¼šå°†ä¼ä¸šæŒ‰è¥æ”¶è§„æ¨¡åˆ†ç»„ï¼Œä¾¿äºåœ¨åŒè§„æ¨¡ä¼ä¸šé—´è¿›è¡Œæ¯”è¾ƒ
        # åŒºé—´åˆ’åˆ†ä¾æ®ï¼š
        # 1. 0-10Mï¼šåˆåˆ›æœŸä¼ä¸š
        # 2. 10-50Mï¼šæˆé•¿æœŸä¼ä¸š
        # 3. 50-100Mï¼šç¨³å®šæœŸä¼ä¸š
        # 4. 100-500Mï¼šæ‰©å¼ æœŸä¼ä¸š
        # 5. 500M+ï¼šæˆç†ŸæœŸä¼ä¸š
        revenue_bins = [0, 10, 50, 100, 500, float('inf')]
        revenue_labels = ['0-10M', '10-50M', '50-100M', '100-500M', '500M+']
        df['è¥æ”¶åŒºé—´'] = pd.cut(df[revenue_col], bins=revenue_bins, labels=revenue_labels)
        
        # è®¡ç®—æ¯ä¸ªè¥æ”¶åŒºé—´çš„èèµ„ä¸­ä½æ•°
        # è¯´æ˜ï¼šä½¿ç”¨ä¸­ä½æ•°è€Œä¸æ˜¯å¹³å‡å€¼ï¼Œé¿å…å¼‚å¸¸å€¼çš„å½±å“
        # åˆ†åˆ«è®¡ç®—ä¸Šè½®èèµ„å’Œç´¯è®¡èèµ„çš„ä¸­ä½æ•°ï¼Œä½œä¸ºè¯¥è§„æ¨¡ä¼ä¸šçš„"æ­£å¸¸"èèµ„æ°´å¹³
        median_funding = df.groupby('è¥æ”¶åŒºé—´')[funding_col].median()
        median_total_funding = df.groupby('è¥æ”¶åŒºé—´')[total_funding_col].median()
        
        # è®¡ç®—èèµ„æ³¡æ²«æŒ‡æ•°
        # è¯´æ˜ï¼šæ³¡æ²«æŒ‡æ•°åæ˜ ä¼ä¸šåœ¨ç›¸åŒè¥æ”¶è§„æ¨¡ä¸‹çš„èèµ„æ°´å¹³
        # è®¡ç®—æ–¹æ³•ï¼š
        # 1. ä¸Šè½®èèµ„æ¯”å€¼ = ä¼ä¸šä¸Šè½®èèµ„é¢ / æ‰€åœ¨åŒºé—´ä¸Šè½®èèµ„ä¸­ä½æ•°
        # 2. ç´¯è®¡èèµ„æ¯”å€¼ = ä¼ä¸šç´¯è®¡èèµ„é¢ / æ‰€åœ¨åŒºé—´ç´¯è®¡èèµ„ä¸­ä½æ•°
        # 3. ç»¼åˆæ³¡æ²«æŒ‡æ•° = (ä¸Šè½®èèµ„æ¯”å€¼ + ç´¯è®¡èèµ„æ¯”å€¼) / 2
        # æŒ‡æ•°å«ä¹‰ï¼š
        # - æŒ‡æ•°=1ï¼šèèµ„æ°´å¹³ä¸åŒè§„æ¨¡ä¼ä¸šç›¸å½“
        # - æŒ‡æ•°>1ï¼šèèµ„æ°´å¹³é«˜äºåŒè§„æ¨¡ä¼ä¸š
        # - æŒ‡æ•°<1ï¼šèèµ„æ°´å¹³ä½äºåŒè§„æ¨¡ä¼ä¸š
        df['èèµ„æ³¡æ²«æŒ‡æ•°'] = 0.0
        for interval in revenue_labels:
            mask = df['è¥æ”¶åŒºé—´'] == interval
            if mask.any():
                # è®¡ç®—ä¸Šè½®èèµ„é¢ä¸åŒºé—´ä¸­ä½æ•°çš„æ¯”å€¼
                funding_ratio = df.loc[mask, funding_col] / median_funding[interval]
                # è®¡ç®—ç´¯è®¡èèµ„é¢ä¸åŒºé—´ä¸­ä½æ•°çš„æ¯”å€¼
                total_funding_ratio = df.loc[mask, total_funding_col] / median_total_funding[interval]
                # ç»¼åˆæ³¡æ²«æŒ‡æ•° = (ä¸Šè½®èèµ„æ¯”å€¼ + ç´¯è®¡èèµ„æ¯”å€¼) / 2
                df.loc[mask, 'èèµ„æ³¡æ²«æŒ‡æ•°'] = (funding_ratio + total_funding_ratio) / 2
        
        # æ ¹æ®èèµ„æ³¡æ²«æŒ‡æ•°åˆ¤æ–­å‘å±•é˜¶æ®µ
        # è¯´æ˜ï¼šå‘å±•é˜¶æ®µåˆ¤æ–­æ ‡å‡†åŸºäºèèµ„æ³¡æ²«æŒ‡æ•°
        # åˆ¤æ–­ä¾æ®ï¼š
        # 1. æ­£å¸¸æœŸï¼ˆæŒ‡æ•°â‰¤1.5ï¼‰ï¼š
        #    - èèµ„æ°´å¹³åœ¨åˆç†èŒƒå›´å†…
        #    - ä¸åŒè§„æ¨¡ä¼ä¸šèèµ„æ°´å¹³ç›¸è¿‘
        #    - å‘å±•è¾ƒä¸ºç¨³å¥
        # 2. æ‰©å¼ æœŸï¼ˆ1.5<æŒ‡æ•°â‰¤3.0ï¼‰ï¼š
        #    - èèµ„æ°´å¹³æ˜¾è‘—é«˜äºåŒè§„æ¨¡ä¼ä¸š
        #    - å¯èƒ½å­˜åœ¨å¸‚åœºæ‰©å¼ æˆ–æŠ€æœ¯çªç ´
        #    - éœ€è¦å…³æ³¨å…¶å‘å±•æŒç»­æ€§
        # 3. æ³¡æ²«æœŸï¼ˆæŒ‡æ•°>3.0ï¼‰ï¼š
        #    - èèµ„æ°´å¹³è¿œé«˜äºåŒè§„æ¨¡ä¼ä¸š
        #    - å¯èƒ½å­˜åœ¨ä¼°å€¼æ³¡æ²«
        #    - éœ€è¦è­¦æƒ•æŠ•èµ„é£é™©
        df['å‘å±•é˜¶æ®µ'] = 'æ­£å¸¸æœŸ'
        df.loc[df['èèµ„æ³¡æ²«æŒ‡æ•°'] > 1.5, 'å‘å±•é˜¶æ®µ'] = 'æ‰©å¼ æœŸ'  # èèµ„æ³¡æ²«æŒ‡æ•°>1.5ä¸ºæ‰©å¼ æœŸ
        df.loc[df['èèµ„æ³¡æ²«æŒ‡æ•°'] > 3.0, 'å‘å±•é˜¶æ®µ'] = 'æ³¡æ²«æœŸ'  # èèµ„æ³¡æ²«æŒ‡æ•°>3.0ä¸ºæ³¡æ²«æœŸ
        
        # æ˜¾ç¤ºå„è¥æ”¶åŒºé—´çš„èèµ„ä¸­ä½æ•°
        # è¯´æ˜ï¼šå±•ç¤ºä¸åŒè§„æ¨¡ä¼ä¸šçš„"æ­£å¸¸"èèµ„æ°´å¹³
        # ç”¨é€”ï¼š
        # 1. äº†è§£å„è§„æ¨¡ä¼ä¸šçš„èèµ„åŸºå‡†
        # 2. åˆ¤æ–­ä¼ä¸šèèµ„æ˜¯å¦å¼‚å¸¸
        # 3. ä¸ºæŠ•èµ„å†³ç­–æä¾›å‚è€ƒ
        st.write("ğŸ“Š å„è¥æ”¶åŒºé—´çš„èèµ„ä¸­ä½æ•°ï¼š")
        median_df = pd.DataFrame({
            'è¥æ”¶åŒºé—´': revenue_labels,
            'ä¸Šè½®èèµ„ä¸­ä½æ•°': median_funding,
            'ç´¯è®¡èèµ„ä¸­ä½æ•°': median_total_funding
        })
        st.dataframe(median_df)
        
        # æ˜¾ç¤ºèèµ„æ³¡æ²«æŒ‡æ•°åˆ†å¸ƒ
        # è¯´æ˜ï¼šå±•ç¤ºæ‰€æœ‰ä¼ä¸šçš„èèµ„æ³¡æ²«æŒ‡æ•°åˆ†å¸ƒæƒ…å†µ
        # åˆ†æè¦ç‚¹ï¼š
        # 1. å‡å€¼ï¼šåæ˜ æ•´ä½“èèµ„æ°´å¹³
        # 2. æ ‡å‡†å·®ï¼šåæ˜ èèµ„æ°´å¹³çš„ç¦»æ•£ç¨‹åº¦
        # 3. åˆ†ä½æ•°ï¼šå¸®åŠ©ç¡®å®šåˆ¤æ–­é˜ˆå€¼
        st.write("ğŸ“ˆ èèµ„æ³¡æ²«æŒ‡æ•°åˆ†å¸ƒï¼š")
        st.write(df['èèµ„æ³¡æ²«æŒ‡æ•°'].describe())
        
        # æ˜¾ç¤ºå‘å±•é˜¶æ®µåˆ¤æ–­ç»“æœ
        # è¯´æ˜ï¼šå±•ç¤ºæ¯ä¸ªä¼ä¸šçš„å‘å±•é˜¶æ®µåˆ¤æ–­ç»“æœ
        # åŒ…å«ä¿¡æ¯ï¼š
        # 1. ä¼ä¸šåŸºæœ¬ä¿¡æ¯ï¼ˆå…¬å¸åã€è¡Œä¸šï¼‰
        # 2. è´¢åŠ¡æ•°æ®ï¼ˆè¥æ”¶ã€èèµ„é¢ï¼‰
        # 3. åˆ†æç»“æœï¼ˆè¥æ”¶åŒºé—´ã€æ³¡æ²«æŒ‡æ•°ã€å‘å±•é˜¶æ®µï¼‰
        st.write("ğŸ“‹ å‘å±•é˜¶æ®µåˆ¤æ–­ç»“æœï¼š")
        display_df = df[text_cols + [revenue_col, 'è¥æ”¶åŒºé—´', funding_col, total_funding_col, 'èèµ„æ³¡æ²«æŒ‡æ•°', 'å‘å±•é˜¶æ®µ']].copy()
        # ç¡®ä¿æ‰€æœ‰æ•°å€¼åˆ—éƒ½æ˜¯floatç±»å‹
        for col in [revenue_col, funding_col, total_funding_col, 'èèµ„æ³¡æ²«æŒ‡æ•°']:
            display_df[col] = pd.to_numeric(display_df[col], errors='coerce')
        # ç¡®ä¿æ–‡æœ¬åˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹
        for col in text_cols + ['è¥æ”¶åŒºé—´', 'å‘å±•é˜¶æ®µ']:
            display_df[col] = display_df[col].astype(str)
        st.dataframe(display_df)
        
        # å‘å±•é˜¶æ®µè¯´æ˜
        st.write("""
        ğŸ“ å‘å±•é˜¶æ®µåˆ¤æ–­è¯´æ˜ï¼š
        1. åˆ¤æ–­æ–¹æ³•ï¼š
           - æŒ‰è¥æ”¶åŒºé—´åˆ†ç»„ï¼ˆ0-10M, 10-50M, 50-100M, 100-500M, 500M+ï¼‰
           - è®¡ç®—æ¯ä¸ªè¥æ”¶åŒºé—´çš„èèµ„ä¸­ä½æ•°
           - è®¡ç®—å„å…¬å¸çš„èèµ„æ³¡æ²«æŒ‡æ•° = (ä¸Šè½®èèµ„/åŒºé—´ä¸­ä½æ•° + ç´¯è®¡èèµ„/åŒºé—´ä¸­ä½æ•°) / 2
        
        2. åˆ¤æ–­æ ‡å‡†ï¼š
           - æ­£å¸¸æœŸï¼šèèµ„æ³¡æ²«æŒ‡æ•° â‰¤ 1.5
           - æ‰©å¼ æœŸï¼š1.5 < èèµ„æ³¡æ²«æŒ‡æ•° â‰¤ 3.0
           - æ³¡æ²«æœŸï¼šèèµ„æ³¡æ²«æŒ‡æ•° > 3.0
        
        3. åˆ¤æ–­æ„ä¹‰ï¼š
           - åæ˜ äº†ä¼ä¸šåœ¨ç›¸åŒè¥æ”¶è§„æ¨¡ä¸‹çš„èèµ„æ°´å¹³
           - å¯ä»¥è¯†åˆ«å‡ºèèµ„å¼‚å¸¸çš„ä¼ä¸š
           - è€ƒè™‘äº†ä¸åŒè§„æ¨¡ä¼ä¸šçš„ç‰¹ç‚¹
        
        4. åˆ†æå±€é™æ€§ï¼š
           - æœªè€ƒè™‘è¡Œä¸šå·®å¼‚
           - æœªè€ƒè™‘ä¼ä¸šå‘å±•é˜¶æ®µ
           - æœªè€ƒè™‘å¸‚åœºç¯å¢ƒå› ç´ 
        """)
    except Exception as e:
        st.error(f"å‘å±•é˜¶æ®µåˆ¤æ–­é”™è¯¯: {str(e)}")
        st.write("é”™è¯¯æ—¶çš„æ•°æ®:")
        st.dataframe(df.head().astype(str))
        st.stop()

    # æ˜¾ç¤ºåŒ…å«å…¬å¸åå’Œè¡Œä¸šçš„æ•°æ®é¢„è§ˆ
    st.subheader("ğŸ” æ•°æ®é¢„è§ˆ")
    display_df = df[text_cols + ['å¢é•¿ç‡', 'å‘å±•é˜¶æ®µ']].copy()
    for col in display_df.columns:
        display_df[col] = display_df[col].astype(str)
    st.dataframe(display_df.head())

    # æè¿°ç»Ÿè®¡ï¼ˆä»…æ•°å€¼åˆ—ï¼‰
    st.subheader("ğŸ“ˆ æè¿°æ€§ç»Ÿè®¡")
    st.dataframe(df[numeric_cols].describe().astype(str))

    # é˜¶æ®µåˆ†å¸ƒç»Ÿè®¡
    st.subheader("ğŸ“Š å‘å±•é˜¶æ®µåˆ†å¸ƒ")
    stage_counts = df['å‘å±•é˜¶æ®µ'].value_counts()
    st.bar_chart(stage_counts)

    # æ˜¾ç¤ºå„é˜¶æ®µå…¬å¸è¯¦æƒ…
    st.subheader("ğŸ“‹ å„é˜¶æ®µå…¬å¸è¯¦æƒ…")
    for stage in ['æ­£å¸¸æœŸ', 'æ‰©å¼ æœŸ', 'æ³¡æ²«æœŸ']:
        st.write(f"### {stage}å…¬å¸åˆ—è¡¨")
        stage_companies = df[df['å‘å±•é˜¶æ®µ'] == stage][text_cols + ['å¢é•¿ç‡']]
        display_df = stage_companies.copy()
        for col in display_df.columns:
            display_df[col] = display_df[col].astype(str)
        st.dataframe(display_df)

    # ------------------------
    # ç›¸å…³æ€§åˆ†æ + æ˜¾è‘—æ€§æ ‡æ³¨
    # ------------------------
    st.subheader("ğŸ“ ç›¸å…³æ€§åˆ†æï¼ˆçš®å°”é€Šï¼‰")

    # åªé€‰æ‹©æ•°å€¼åˆ—è¿›è¡Œç›¸å…³æ€§åˆ†æ
    corr_matrix = df[numeric_cols].corr()
    st.write("ğŸ“Š ç›¸å…³çŸ©é˜µï¼š")
    st.dataframe(corr_matrix)

    # ç›¸å…³æ€§çƒ­å›¾
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax, fmt='.2f')
    plt.title('Correlation Heatmap', fontsize=12)

    # å®šä¹‰åˆ—åæ˜ å°„
    column_mapping = {
        'å¹´è¥æ”¶ä¼°æµ‹\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰': 'Annual Revenue (Million USD)',
        'ä¸Šè½®èèµ„é¢\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰': 'Last Round Funding (Million USD)',
        'ç´¯è®¡èèµ„é¢\nï¼ˆç™¾ä¸‡ç¾å…ƒï¼‰': 'Total Funding (Million USD)'
    }

    # è®¾ç½®è‹±æ–‡æ ‡ç­¾
    ax.set_xticklabels([column_mapping.get(col, col) for col in numeric_cols], rotation=45, ha='right')
    ax.set_yticklabels([column_mapping.get(col, col) for col in numeric_cols], rotation=0)
    st.pyplot(fig)

    # æ˜¾è‘—æ€§æ£€éªŒ
    st.write("ğŸ§ª æ˜¾è‘—æ€§ï¼ˆp < 0.05ï¼‰")
    cols = numeric_cols
    sig_result = []
    for i in range(len(cols)):
        for j in range(i + 1, len(cols)):
            r, p = pearsonr(df[cols[i]], df[cols[j]])
            sig_result.append((cols[i], cols[j], round(r, 3), "{:.3e}".format(p), "âœ…" if p < 0.05 else "âŒ"))
    sig_df = pd.DataFrame(sig_result, columns=["å˜é‡1", "å˜é‡2", "ç›¸å…³ç³»æ•°", "på€¼", "æ˜¾è‘—æ€§"])
    st.dataframe(sig_df)

    # ------------------------
    # å¼‚å¸¸å€¼æ£€æµ‹
    # ------------------------
    st.subheader("ğŸš¨ å¼‚å¸¸å€¼æ£€æµ‹")

    # åªé€‰æ‹©æ•°å€¼åˆ—è¿›è¡Œå¼‚å¸¸å€¼æ£€æµ‹
    numeric_df = df[numeric_cols]

    # æ–¹æ³•1ï¼šZ-score
    z_scores = numeric_df.apply(zscore)
    z_outliers = (z_scores.abs() > 3).any(axis=1)

    # æ–¹æ³•2ï¼šIQR
    Q1 = numeric_df.quantile(0.25)
    Q3 = numeric_df.quantile(0.75)
    IQR = Q3 - Q1
    iqr_outliers = ((numeric_df < (Q1 - 1.5 * IQR)) | (numeric_df > (Q3 + 1.5 * IQR))).any(axis=1)

    # æ–¹æ³•3ï¼šIsolation Forest
    iso = IsolationForest(contamination=0.05, random_state=42)
    iso_outliers = iso.fit_predict(numeric_df)
    iso_mask = iso_outliers == -1

    # æ±‡æ€»
    combined_outliers = z_outliers | iqr_outliers | iso_mask
    outlier_df = df[text_cols + numeric_cols + ['å¢é•¿ç‡', 'å‘å±•é˜¶æ®µ']][combined_outliers]

    st.write(f"ğŸ”º Z-score å¼‚å¸¸å€¼æ•°é‡: {z_outliers.sum()}")
    st.write(f"ğŸ”º IQR å¼‚å¸¸å€¼æ•°é‡: {iqr_outliers.sum()}")
    st.write(f"ğŸ”º Isolation Forest å¼‚å¸¸å€¼æ•°é‡: {np.sum(iso_mask)}")
    st.write(f"âœ… åˆå¹¶å¼‚å¸¸å€¼æ•°é‡ï¼ˆå»é‡åï¼‰: {combined_outliers.sum()}")

    st.dataframe(outlier_df)

    # ä¸‹è½½æŒ‰é’®
    to_download = outlier_df.copy()
    csv = to_download.to_csv(index=False).encode()
    st.download_button("ğŸ“¥ ä¸‹è½½å¼‚å¸¸å€¼æ•°æ®", csv, "å¼‚å¸¸å€¼ç»“æœ.csv", "text/csv")

    # ------------------------
    # PCA å¯è§†åŒ–
    # ------------------------
    st.subheader("ğŸ§¬ PCA Dimensionality Reduction Visualization")

    # åªä½¿ç”¨æ•°å€¼åˆ—è¿›è¡ŒPCAåˆ†æ
    pca = PCA(n_components=2)
    components = pca.fit_transform(numeric_df)

    fig2, ax2 = plt.subplots(figsize=(10, 8))
    scatter = ax2.scatter(components[:, 0], components[:, 1], 
                         c=df['å¢é•¿ç‡'], cmap='viridis', alpha=0.7)
    plt.colorbar(scatter, label='Growth Rate (%)')

    # æ·»åŠ é˜¶æ®µæ ‡ç­¾
    stage_mapping = {
        'æ­£å¸¸æœŸ': 'Normal Period',
        'æ‰©å¼ æœŸ': 'Expansion Period',
        'æ³¡æ²«æœŸ': 'Bubble Period'
    }

    # ä½¿ç”¨è‹±æ–‡æ ‡ç­¾
    for stage in df['å‘å±•é˜¶æ®µ'].unique():
        mask = df['å‘å±•é˜¶æ®µ'] == stage
        ax2.scatter(components[mask, 0], components[mask, 1], 
                   label=stage_mapping.get(stage, stage), alpha=0.7)

    ax2.set_xlabel(f"First Principal Component (Explained Variance: {pca.explained_variance_ratio_[0]*100:.2f}%)", fontsize=10)
    ax2.set_ylabel(f"Second Principal Component (Explained Variance: {pca.explained_variance_ratio_[1]*100:.2f}%)", fontsize=10)
    ax2.set_title("PCA Results and Development Stage Distribution", fontsize=12)
    ax2.legend(fontsize=10)
    st.pyplot(fig2)

    # æ·»åŠ é˜¶æ®µåˆ†ææ€»ç»“
    st.subheader("ğŸ“‹ é˜¶æ®µåˆ†ææ€»ç»“")
    st.write("""
    1. æ‰©å¼ æœŸç‰¹å¾ï¼š
       - å¢é•¿ç‡ > 20%
       - é€šå¸¸ä¼´éšè¾ƒé«˜çš„å¸‚åœºå…³æ³¨åº¦
       - å¯èƒ½å­˜åœ¨ä¼°å€¼æ³¡æ²«é£é™©

    2. æ³¡æ²«æœŸç‰¹å¾ï¼š
       - å¢é•¿ç‡ > 50%
       - å¯èƒ½å­˜åœ¨è¿‡åº¦æŠ•æœº
       - éœ€è¦è­¦æƒ•å¸‚åœºå›è°ƒé£é™©

    3. æ­£å¸¸æœŸç‰¹å¾ï¼š
       - å¢é•¿ç‡ç›¸å¯¹ç¨³å®š
       - å¸‚åœºè¡¨ç°è¾ƒä¸ºç†æ€§
       - æŠ•èµ„é£é™©ç›¸å¯¹è¾ƒä½
    """)

    # æŸ¥çœ‹ç³»ç»Ÿä¸­å·²å®‰è£…çš„ä¸­æ–‡å­—ä½“
    fonts = [f.name for f in matplotlib.font_manager.fontManager.ttflist if 'SimHei' in f.name or 'YaHei' in f.name or 'KaiTi' in f.name]
    print(fonts)